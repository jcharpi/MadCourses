# SkillÂ CourseÂ Aggregator

Automatically rank university courses against a set of skill phrases using sentence embeddings.

The script **`skill_course_aggregator.py`** turns a plainâ€‘text CSV of course titles & descriptions into recommendations that best match your chosen skills. It downloads the `allâ€‘mpnetâ€‘baseâ€‘v2` embedding model on first run and caches course vectors, so subsequent runs are instant.

---

## âœ¨Â Features

| Feature | Details |
|---------|---------|
| **Semantic matching** | Uses normalized cosineâ€‘similarity between skill vectors and course vectors (Sentenceâ€‘Transformers) |
| **Batch ranking** | Returns topâ€‘k courses _per skill_ **and** overall centroid ranking |
| **Disk cache** | Persists course embeddings to a companion `.npy` file; recompute only when the CSV changes |
| **Configurable** | Change skills, model, `TOP_K`, and CSV path at the top of the script |

---

## ðŸš€Â QuickÂ Start

### 1.Â Prerequisites

* **PythonÂ 3.9 â€“Â 3.12** (check with `python --version`)
* An internet connection the first time you run the script (â‰ˆ830â€¯MB model download)

### 2.Â Clone &Â setup

```bash
# Clone your repo or copy the files into a folder
cd skillâ€‘courseâ€‘aggregator

# Create & activate a fresh virtual environment
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS / Linux
source .venv/bin/activate

# Always upgrade pip & wheel first
python -m pip install --upgrade pip wheel

# Install required packages
pip install -r requirements.txt
```

### 3.Â Prepare your data

Place **`courses.csv`** in the project root. The file **must** contain the columns:

* `Title` â€“â€¯course code or name
* `Description` â€“â€¯oneâ€‘paragraph summary

### 4.Â Run the script

```bash
python skill_course_aggregator.py
```

Sample console output (with the default skills):

```
Skill: 'Building athlete analytics dashboards and user interfaces'
  â†’Â KINES 350 â€“ Sports Data VisualizationÂ (scoreÂ 0.823)
  â†’Â CSÂ 559 â€“ Computer GraphicsÂ (scoreÂ 0.812)
  â€¦

TopÂ 5 courses overall:
  â†’Â STATÂ 471 â€“ Applied RegressionÂ (centroid_scoreÂ 0.812)
  â†’Â KINESÂ 350 â€“ Sports Data VisualizationÂ (centroid_scoreÂ 0.808)
  â€¦
```

The first run may take a minute while the model downloads and the script builds the vector cache. Subsequent runs finish in seconds.

---

## ðŸ› Â Configuration

Open **`skill_course_aggregator.py`** and tweak the block near the top:

```python
CSV_PATH   = Path("./courses.csv")
SKILLS     = ["Build dashboards â€¦", "Implement realâ€‘time â€¦", â€¦]
TOP_K      = 5
MODEL_NAME = "sentence-transformers/all-mpnet-base-v2"
```

* **Changing the CSV path** automatically creates/uses a matching `.npy` cache.
* **Switching to another Sentenceâ€‘Transformer** will download that model on first use.

---

## ðŸ—‚Â ProjectÂ Structure

```
â”‚  README.md
â”‚  requirements.txt
â”‚  skill_course_aggregator.py
â”‚  courses.csv               <- your input data
â”‚  courses.npy               <- autoâ€‘generated embedding cache
â””â”€ .venv/                     <- (optional) virtualâ€‘environment files
```
